{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7th_cassava.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOm/VMPySxoD1pIXUh9rDaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yk-Jeong/Kaggle-Studies/blob/main/7th_cassava.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1/14~1/20) 스터디 7주차: https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-tpu-tensorflow-training/notebook\n"
      ],
      "metadata": {
        "id": "7AcIJxFVKmPX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3ecY4mKKAv7",
        "outputId": "cad0c54d-0816-43bf-8e22-d953616ccee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --queit\n"
          ]
        }
      ],
      "source": [
        "!pip install --queit efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "GTKByvsWNQBA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/qubvel/segmentation_models"
      ],
      "metadata": {
        "id": "1BmNr4Xlthfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d420741-0aad-4a15-cd78-8c5d4707466f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/qubvel/segmentation_models\n",
            "  Cloning https://github.com/qubvel/segmentation_models to /tmp/pip-req-build-rkvb2s69\n",
            "  Running command git clone -q https://github.com/qubvel/segmentation_models /tmp/pip-req-build-rkvb2s69\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2021.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.15.0)\n",
            "Building wheels for collected packages: segmentation-models\n",
            "  Building wheel for segmentation-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segmentation-models: filename=segmentation_models-1.0.1-py3-none-any.whl size=33810 sha256=757a281e0bd63420e302196107995f276a4c477758d2c96301eef3de5d51e7fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y9o0mspt/wheels/02/cd/18/61c0bbb8766acfec68f9d20618886b7b38dfeeb95865b6ba00\n",
            "Successfully built segmentation-models\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle !cp kaggle.json ~/.kaggle/ \n",
        "!cmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC3jB529WVXO",
        "outputId": "8e73963e-1651-46a1-f652-497d86a1f087"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘kaggle.json’: File exists\n",
            "/bin/bash: cmod: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -c cassava-leaf-disease-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXj70cUgWLYu",
        "outputId": "c907d68a-e74b-477d-e949-bc385623fbfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. lib load and memory setting "
      ],
      "metadata": {
        "id": "33Wy2MJhK1cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math, os, re, warnings, random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow.keras import optimizers, applications, Sequential, losses, metrics\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "import efficientnet.tfkeras as efn"
      ],
      "metadata": {
        "id": "w3W0iRD2K0Ej"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed = 0):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "seed = 0\n",
        "seed_everything(seed)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "0NtKClwiNAmy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TPU or GPU detection\n",
        "\n",
        "try: \n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print(f'Running on TPU {tpu.master()}')\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIWc0k8oVtMS",
        "outputId": "2edf075e-3b47-4520-81bf-d6fc781f36e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#params\n",
        "\n",
        "BATCH_SIZE = 16 * REPLICAS\n",
        "LEARNING_RATE = 3e-5 * REPLICAS\n",
        "EPOCHS = 30\n",
        "HEIGHT = 512\n",
        "WIDTH = 512\n",
        "CHANNELS = 3\n",
        "ES_PATIENCE = 10\n",
        "N_FOLDS = 5"
      ],
      "metadata": {
        "id": "S4K63vk9Wm10"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. load data"
      ],
      "metadata": {
        "id": "oH4lOtuCW8zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_data_items(filenames):\n",
        "  n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n",
        "  return np.sum(n)\n",
        "\n",
        "database_base_path = '/kaggle/input/cassava-leaf-disease-classification/'\n",
        "train = pd.read_csv(f'{database_base_path}train.csv')\n",
        "print(f'Train samples: {len(train)}')\n",
        "\n",
        "GCS_PATH = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-tfrecords-center-{HEIGHT}x{WIDTH}') \n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\n",
        "NUM_TRAINING_IMAGES= count_data_items(TRAINING_FILENAMES)\n",
        "\n",
        "print(f'GCS: train images: {NUM_TRAINING_IMAGES}')\n",
        "display(train.head())"
      ],
      "metadata": {
        "id": "wfMoob4GW61b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "0cc2ef90-e231-4435-a8cf-a98f9e02f876"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-28ad0c68f1ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdatabase_base_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/cassava-leaf-disease-classification/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{database_base_path}train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train samples: {len(train)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/cassava-leaf-disease-classification/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = ['Cassava Bacterial Blight', \n",
        "           'Cassava Brown Streak Disease', \n",
        "           'Cassava Green Mottle', \n",
        "           'Cassava Mosaic Disease', \n",
        "           'Healthy']"
      ],
      "metadata": {
        "id": "NgwThejGX_Hi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation "
      ],
      "metadata": {
        "id": "im-ZqWHQyquq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#학습률 향상을 위해 이미지를 리터칭한다 \n",
        "\n",
        "def data_augment(image, label):\n",
        "  p_rotation = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "  p_spatial = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "  p_rotate = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "  p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "  p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "  p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "  p_shear = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "  p_crop = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
        "\n",
        "#shear\n",
        "\n",
        "  if p_shear > .2:\n",
        "    if p_shear > .6:\n",
        "      image = transform_shear(image, HEIGHT, shear = 20.)\n",
        "    else:\n",
        "      image - transform_shear(image, HEIGHT, shear = -20.)\n",
        "  \n",
        "#rotation\n",
        "  if p_rotation > .2:\n",
        "    if p_rotation > .6:\n",
        "      image = transform_rotation(iamge, HEIGHT, rotation = 45.)\n",
        "    else:\n",
        "      image = transform_rotation(iamge, HEIGHT, rotation = -45.)\n",
        "\n",
        "#flips\n",
        "image = tf."
      ],
      "metadata": {
        "id": "cD81sEi7sZc4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xZZF1bn1YIB4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}