{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8th_keras_boston_housing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yk-Jeong/Kaggle-Studies/blob/main/8th_keras_boston_housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=utP3gh9DZI8"
      ],
      "metadata": {
        "id": "2EE21n0lbSqm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj-RA7rQLSC4"
      },
      "source": [
        "# 케라스 보스턴 주택 가격 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1rSC60ILf0U"
      },
      "source": [
        "### modules import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmYcVLNsmFR_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets.boston_housing import load_data #keras dataset으로 존재\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbRqQY1aMMTU"
      },
      "source": [
        "### 데이터 로드\n",
        "- 데이터의 수가 상당히 적기 때문에 테스트 데이터의 비율을 20%로 지정\n",
        "\n",
        "- 13개의 특성을 가짐\n",
        "\n",
        "- 각각의 특성이 모두 다른 스케일, 즉 단위가 모두 다름\n",
        "  - 범죄율: 0~1 사이의 값\n",
        "  - 방의 개수: 3~9 사이의 값(min=3, max=9, *범죄율과 스케일이 다름*)\n",
        "\n",
        "- 정답 레이블은 주택 가격의 중간가격($1000 단위)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWHBrPVTMGyu"
      },
      "source": [
        "tf.random.set_seed(111)\n",
        "(X_train_full, y_train_full), (X_test, y_test) = load_data(path = 'boston_housing.npz', \n",
        "                                                           test_split = 0.2, seed = 111)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCTcnMT6Mgx9"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdisxCBbMbRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d522bfec-8a95-474d-b9dc-698a0d50e3db"
      },
      "source": [
        "print(\"학습 데이터: {}\\t레이블: {}\".format(X_train_full.shape, y_train_full.shape))\n",
        "print(\"테스트 데이터: {}\\t레이블: {}\".format(X_test.shape, y_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(훈련데이터의 데이터/정답 레이블 첫 항목을 출력해본다)*"
      ],
      "metadata": {
        "id": "PfOcSbyYcb1D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjEoDJ6fM4I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22cca68e-bd55-4b23-f6d7-e0278543e03d"
      },
      "source": [
        "print(X_train_full[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.8750e-02 2.8000e+01 1.5040e+01 0.0000e+00 4.6400e-01 6.2110e+00\n",
            " 2.8900e+01 3.6659e+00 4.0000e+00 2.7000e+02 1.8200e+01 3.9633e+02\n",
            " 6.2100e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-V0pQdbNSso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e927fd-3d4e-4aa8-8dd1-61d012c1682f"
      },
      "source": [
        "print(y_train_full[0]) #$1000 단위이므로 *1000 = $25,000"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ZK_dJdOlCu"
      },
      "source": [
        "### 데이터 전처리\n",
        "- Standardization\n",
        "\n",
        "- 특성의 단위가 모두 다르기 때문에 **동일한 범위로 조정**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjRcDM_CNV--"
      },
      "source": [
        "mean = np.mean(X_train_full, axis=0)\n",
        "std = np.std(X_train_full, axis=0)\n",
        "\n",
        "X_train_preprocessed = (X_train_full - mean) / std\n",
        "X_test = (X_test - mean) / mean"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_preprocessed, y_train_full,\n",
        "                                                  test_size = 0.3,\n",
        "                                                  random_state = 111)"
      ],
      "metadata": {
        "id": "UDGbGST1c4lR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1fl37t9PR0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac1bc3d-e80c-4e0e-82e3-37c120833563"
      },
      "source": [
        "print(\"학습 데이터: {}\\t레이블: {}\".format(X_train_full.shape, y_train_full.shape))\n",
        "print(\"학습 데이터: {}\\t레이블: {}\".format(X_train.shape, y_train.shape))\n",
        "print(\"검증 데이터: {}\\t레이블: {}\".format(X_val.shape, y_val.shape))\n",
        "print(\"테스트 데이터: {}\\t레이블: {}\".format(X_test.shape, y_test.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "학습 데이터: (282, 13)\t레이블: (282,)\n",
            "검증 데이터: (122, 13)\t레이블: (122,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*feature가 13개인 것을 확인 가능*"
      ],
      "metadata": {
        "id": "VEDO_WJldh4t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTcwvMqdPynu"
      },
      "source": [
        "### 모델 구성\n",
        "- 학습 데이터가 매우 적은 경우, 모델의 깊이를 깊게 할수록 과대적합(Overfitting)이 일어날 확률이 높음"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*따라서 학습 데이터가 적은 경우에는 모델의 깊이가 지나치게 깊지 않도록 쌓아줄 필요가 있음*"
      ],
      "metadata": {
        "id": "Zd7OWY7wdsUD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P7pAnqUPcCf"
      },
      "source": [
        "model = Sequential([Dense(100, activation = 'relu', input_shape=(13, ), name='dense1'),\n",
        "                    Dense(64, activation = 'relu', name = 'dense2'),\n",
        "                    Dense(32, activation = 'relu', name = 'dense3'),\n",
        "                    Dense(1, name = 'output')]) #결과값은 단일하게 나오므로(주택가격은 회귀모형임) output을 1로 설정"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRi6Vd8WQYyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c7b8d2-7008-4e0a-98bd-1e6e6e032d73"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense1 (Dense)              (None, 100)               1400      \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 64)                6464      \n",
            "                                                                 \n",
            " dense3 (Dense)              (None, 32)                2080      \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,977\n",
            "Trainable params: 9,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-dFvQRGQalM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "159c3cc1-d4bd-40c4-b154-8d6b0df5ed3b"
      },
      "source": [
        "plot_model(model) #img로 확인할 수 있음"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m05yRQmQmFA"
      },
      "source": [
        "### 모델 컴파일(compile)\n",
        "\n",
        "- 회귀 문제에서는 주로 평균제곱오차(MSE, Mean Squared Error)를 손실함수로,  \n",
        "  평균절대오차(MAE, Mean Absolute Error)를 평가지표로 많이 사용!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z2IMfH3QkGv"
      },
      "source": [
        "model.compile(loss = 'mse', #loss 손실함수는 mse\n",
        "              optimizer = Adam(learning_rate = 1e-2),  #학습률을 왜 작은 값으로 두었을까 \n",
        "              metrics = ['mae']) #metrics 평가지표는 mae인 것 유의"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YhN4fzmRQpY"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGA9gPIERPxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbc521a-1690-4eaf-c0d9-51d39c87b343"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs = 300,\n",
        "                    validation_data = (X_val, y_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 51ms/step - loss: 285.1888 - mae: 14.0729 - val_loss: 132.4612 - val_mae: 9.1090\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 60.9891 - mae: 5.9218 - val_loss: 31.4368 - val_mae: 4.4589\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 33.7114 - mae: 4.2293 - val_loss: 22.2753 - val_mae: 3.6017\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 21.5946 - mae: 3.4391 - val_loss: 13.9826 - val_mae: 2.9190\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 16.3538 - mae: 2.8935 - val_loss: 11.7222 - val_mae: 2.7147\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 13.6432 - mae: 2.5889 - val_loss: 10.9746 - val_mae: 2.5883\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 12.6475 - mae: 2.4426 - val_loss: 9.1843 - val_mae: 2.3985\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 12.5112 - mae: 2.5104 - val_loss: 9.8296 - val_mae: 2.4060\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 11.3260 - mae: 2.3506 - val_loss: 8.1732 - val_mae: 2.2383\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 11.1601 - mae: 2.3899 - val_loss: 8.3317 - val_mae: 2.2944\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.3497 - mae: 2.3828 - val_loss: 9.6377 - val_mae: 2.3146\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.4039 - mae: 2.3526 - val_loss: 8.3838 - val_mae: 2.3106\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6115 - mae: 2.1968 - val_loss: 8.4295 - val_mae: 2.2763\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.5119 - mae: 2.1870 - val_loss: 9.0308 - val_mae: 2.4176\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.5966 - mae: 2.0715 - val_loss: 8.1153 - val_mae: 2.2021\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.6300 - mae: 2.1294 - val_loss: 8.3422 - val_mae: 2.2117\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.7119 - mae: 2.1223 - val_loss: 10.9265 - val_mae: 2.6191\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6290 - mae: 2.3363 - val_loss: 8.8320 - val_mae: 2.3394\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.1268 - mae: 2.0547 - val_loss: 7.6580 - val_mae: 2.1378\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1541 - mae: 1.8875 - val_loss: 9.4983 - val_mae: 2.3932\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6636 - mae: 2.0445 - val_loss: 7.8261 - val_mae: 2.1954\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.2970 - mae: 1.9602 - val_loss: 9.3017 - val_mae: 2.4027\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6526 - mae: 2.0690 - val_loss: 8.9616 - val_mae: 2.2930\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1070 - mae: 1.9766 - val_loss: 9.3341 - val_mae: 2.4466\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.2434 - mae: 1.9778 - val_loss: 8.0337 - val_mae: 2.1472\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.0202 - mae: 1.9266 - val_loss: 9.5019 - val_mae: 2.4783\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7250 - mae: 2.0076 - val_loss: 8.8930 - val_mae: 2.2959\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.0065 - mae: 1.8350 - val_loss: 8.3984 - val_mae: 2.3100\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.2788 - mae: 1.7311 - val_loss: 7.6616 - val_mae: 2.1417\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7267 - mae: 1.6697 - val_loss: 8.6152 - val_mae: 2.2187\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.3804 - mae: 1.5647 - val_loss: 8.6618 - val_mae: 2.2299\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 4.1287 - mae: 1.5456 - val_loss: 9.1019 - val_mae: 2.3014\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 4.2564 - mae: 1.5684 - val_loss: 8.3172 - val_mae: 2.2020\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.0268 - mae: 1.4928 - val_loss: 7.7193 - val_mae: 2.1266\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.3587 - mae: 1.5772 - val_loss: 8.6461 - val_mae: 2.2870\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 3.7208 - mae: 1.4466 - val_loss: 8.7016 - val_mae: 2.2682\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.4474 - mae: 1.3969 - val_loss: 7.7028 - val_mae: 2.1663\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 3.5473 - mae: 1.4469 - val_loss: 9.2293 - val_mae: 2.3254\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.1164 - mae: 1.5364 - val_loss: 7.5516 - val_mae: 2.1471\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.1612 - mae: 1.5391 - val_loss: 9.0860 - val_mae: 2.2800\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 5.8975 - mae: 1.7234 - val_loss: 14.1046 - val_mae: 2.7156\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.4876 - mae: 2.0237 - val_loss: 11.8633 - val_mae: 2.5463\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7282 - mae: 1.9226 - val_loss: 11.1312 - val_mae: 2.3476\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.5698 - mae: 1.8489 - val_loss: 10.5545 - val_mae: 2.5355\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 5.9226 - mae: 1.8198 - val_loss: 9.9145 - val_mae: 2.5194\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 5.3605 - mae: 1.8161 - val_loss: 10.8243 - val_mae: 2.4174\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.6700 - mae: 1.7251 - val_loss: 8.7168 - val_mae: 2.1118\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5694 - mae: 1.6758 - val_loss: 10.2233 - val_mae: 2.3588\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.5289 - mae: 1.4010 - val_loss: 8.8952 - val_mae: 2.2460\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.3496 - mae: 1.3750 - val_loss: 8.7896 - val_mae: 2.2495\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 3.1284 - mae: 1.3290 - val_loss: 9.6549 - val_mae: 2.3212\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 3.3039 - mae: 1.3504 - val_loss: 10.4077 - val_mae: 2.4115\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.9633 - mae: 1.3231 - val_loss: 8.4694 - val_mae: 2.1882\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.7208 - mae: 1.2373 - val_loss: 10.2249 - val_mae: 2.3849\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.6439 - mae: 1.2001 - val_loss: 9.0479 - val_mae: 2.2614\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.7171 - mae: 1.2412 - val_loss: 9.0285 - val_mae: 2.3163\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.8780 - mae: 1.2970 - val_loss: 9.9899 - val_mae: 2.3006\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9088 - mae: 1.2944 - val_loss: 9.3331 - val_mae: 2.2928\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.1556 - mae: 1.3606 - val_loss: 8.6352 - val_mae: 2.2724\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2.9424 - mae: 1.3052 - val_loss: 9.0182 - val_mae: 2.3817\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.7571 - mae: 1.2281 - val_loss: 9.6503 - val_mae: 2.2940\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.6481 - mae: 1.2213 - val_loss: 10.2703 - val_mae: 2.3134\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.8007 - mae: 1.2464 - val_loss: 11.5448 - val_mae: 2.3868\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.8765 - mae: 1.2628 - val_loss: 7.8443 - val_mae: 2.1077\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.5797 - mae: 1.2197 - val_loss: 10.0385 - val_mae: 2.4065\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.8164 - mae: 1.2721 - val_loss: 8.8858 - val_mae: 2.3324\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3793 - mae: 1.3949 - val_loss: 10.0863 - val_mae: 2.3325\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1334 - mae: 1.3416 - val_loss: 9.1890 - val_mae: 2.2378\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2.7248 - mae: 1.2136 - val_loss: 9.8590 - val_mae: 2.2711\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.3818 - mae: 1.1229 - val_loss: 9.3658 - val_mae: 2.2573\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 2.5122 - mae: 1.1780 - val_loss: 9.0746 - val_mae: 2.2417\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2.8295 - mae: 1.2673 - val_loss: 14.5440 - val_mae: 2.8623\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.5592 - mae: 1.4149 - val_loss: 9.4024 - val_mae: 2.3350\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.7696 - mae: 1.2703 - val_loss: 9.8979 - val_mae: 2.3131\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.2436 - mae: 1.1286 - val_loss: 10.1262 - val_mae: 2.2962\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2.3050 - mae: 1.1445 - val_loss: 10.4645 - val_mae: 2.4467\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 2.4235 - mae: 1.1813 - val_loss: 11.7117 - val_mae: 2.5700\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.6634 - mae: 1.2345 - val_loss: 11.6203 - val_mae: 2.4593\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 2.5594 - mae: 1.1984 - val_loss: 9.0527 - val_mae: 2.2232\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.0361 - mae: 1.3473 - val_loss: 15.3192 - val_mae: 2.8569\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.2432 - mae: 1.6886 - val_loss: 8.5993 - val_mae: 2.1877\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 5.4689 - mae: 1.6499 - val_loss: 19.4235 - val_mae: 3.0101\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.6341 - mae: 2.0480 - val_loss: 9.5406 - val_mae: 2.3381\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.0174 - mae: 1.5725 - val_loss: 9.8996 - val_mae: 2.3267\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.1671 - mae: 1.3826 - val_loss: 9.7036 - val_mae: 2.4429\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 3.1534 - mae: 1.2988 - val_loss: 11.2541 - val_mae: 2.3611\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2.4493 - mae: 1.1906 - val_loss: 10.7775 - val_mae: 2.3489\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2.2138 - mae: 1.1236 - val_loss: 9.3196 - val_mae: 2.2731\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 2.5308 - mae: 1.1848 - val_loss: 10.5826 - val_mae: 2.3135\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.3683 - mae: 1.2970 - val_loss: 10.4796 - val_mae: 2.4373\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.3313 - mae: 1.3546 - val_loss: 8.4616 - val_mae: 2.1069\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 2.3971 - mae: 1.1783 - val_loss: 8.5146 - val_mae: 2.2767\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4490 - mae: 1.1593 - val_loss: 11.2875 - val_mae: 2.4678\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6889 - mae: 1.1993 - val_loss: 9.0512 - val_mae: 2.1603\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4708 - mae: 1.2077 - val_loss: 10.2199 - val_mae: 2.3292\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4068 - mae: 1.1815 - val_loss: 9.8834 - val_mae: 2.3692\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 2.4002 - mae: 1.2268 - val_loss: 8.5077 - val_mae: 2.2729\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 2.9534 - mae: 1.2740 - val_loss: 10.6069 - val_mae: 2.4381\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.5216 - mae: 1.4921 - val_loss: 7.6226 - val_mae: 2.1386\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 3.0655 - mae: 1.3576 - val_loss: 13.2123 - val_mae: 2.7192\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 2.8318 - mae: 1.2687 - val_loss: 11.1519 - val_mae: 2.4405\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 2.2412 - mae: 1.1342 - val_loss: 8.3464 - val_mae: 2.2781\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 2.6984 - mae: 1.2584 - val_loss: 13.4355 - val_mae: 2.5925\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 2.8748 - mae: 1.2671 - val_loss: 11.4898 - val_mae: 2.3909\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 2.8787 - mae: 1.2167 - val_loss: 11.0240 - val_mae: 2.4362\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 2.9803 - mae: 1.3276 - val_loss: 13.4915 - val_mae: 2.8231\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 3.6583 - mae: 1.5248 - val_loss: 9.7116 - val_mae: 2.3223\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 2.2276 - mae: 1.0796 - val_loss: 9.6829 - val_mae: 2.2241\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.9147 - mae: 1.0205 - val_loss: 10.6154 - val_mae: 2.2966\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.4704 - mae: 0.8819 - val_loss: 9.1596 - val_mae: 2.2168\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.5662 - mae: 0.9292 - val_loss: 9.7795 - val_mae: 2.2799\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.4589 - mae: 0.8731 - val_loss: 9.8951 - val_mae: 2.2951\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.3554 - mae: 0.8381 - val_loss: 10.0044 - val_mae: 2.2486\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.5238 - mae: 0.9141 - val_loss: 11.0705 - val_mae: 2.3368\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.4571 - mae: 0.8965 - val_loss: 8.2830 - val_mae: 2.1488\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1.6981 - mae: 0.9518 - val_loss: 10.6390 - val_mae: 2.4307\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.6584 - mae: 0.9253 - val_loss: 11.0551 - val_mae: 2.3367\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.3905 - mae: 0.8854 - val_loss: 10.0462 - val_mae: 2.2473\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.6859 - mae: 0.9671 - val_loss: 11.3387 - val_mae: 2.5616\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 2.1025 - mae: 1.0655 - val_loss: 9.4397 - val_mae: 2.3189\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.5308 - mae: 0.9220 - val_loss: 9.8855 - val_mae: 2.2269\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 1.6079 - mae: 0.9382 - val_loss: 11.0234 - val_mae: 2.4480\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.9918 - mae: 1.0009 - val_loss: 12.0338 - val_mae: 2.5677\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.5520 - mae: 0.9375 - val_loss: 9.3995 - val_mae: 2.1855\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.4291 - mae: 0.8731 - val_loss: 12.3123 - val_mae: 2.4807\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.3978 - mae: 0.8415 - val_loss: 9.2733 - val_mae: 2.2665\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.2989 - mae: 0.8397 - val_loss: 11.1641 - val_mae: 2.3487\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.2275 - mae: 0.8083 - val_loss: 9.8776 - val_mae: 2.2821\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.2823 - mae: 0.8151 - val_loss: 10.1076 - val_mae: 2.3444\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 1.7356 - mae: 1.0027 - val_loss: 9.9785 - val_mae: 2.3835\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.8429 - mae: 1.0000 - val_loss: 11.6445 - val_mae: 2.4221\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 1.2934 - mae: 0.8579 - val_loss: 12.0605 - val_mae: 2.4589\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.8380 - mae: 1.0313 - val_loss: 11.3691 - val_mae: 2.5150\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.3721 - mae: 0.8598 - val_loss: 9.5387 - val_mae: 2.2562\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1.1272 - mae: 0.7810 - val_loss: 11.1946 - val_mae: 2.3711\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.0736 - mae: 0.7467 - val_loss: 11.1561 - val_mae: 2.3795\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 1.0988 - mae: 0.7853 - val_loss: 11.7137 - val_mae: 2.4292\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 1.6157 - mae: 0.9313 - val_loss: 11.2830 - val_mae: 2.3896\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 1.9579 - mae: 1.0833 - val_loss: 11.5408 - val_mae: 2.4144\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 1.7763 - mae: 1.0189 - val_loss: 11.4173 - val_mae: 2.3581\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.4645 - mae: 0.9007 - val_loss: 10.3499 - val_mae: 2.3751\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.5032 - mae: 0.9081 - val_loss: 9.9736 - val_mae: 2.2297\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 1.1775 - mae: 0.7800 - val_loss: 11.7317 - val_mae: 2.3495\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.6800 - mae: 1.0253 - val_loss: 11.8033 - val_mae: 2.4552\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 1.5964 - mae: 0.9591 - val_loss: 11.4509 - val_mae: 2.4285\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.3537 - mae: 0.8885 - val_loss: 9.8530 - val_mae: 2.2676\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.2323 - mae: 0.8100 - val_loss: 11.0658 - val_mae: 2.3914\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.6964 - mae: 0.9728 - val_loss: 11.4690 - val_mae: 2.5149\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.9002 - mae: 1.0880 - val_loss: 10.4042 - val_mae: 2.3241\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.9525 - mae: 1.0708 - val_loss: 11.2086 - val_mae: 2.3304\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.2193 - mae: 0.8133 - val_loss: 11.3790 - val_mae: 2.4516\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 1.3997 - mae: 0.8753 - val_loss: 9.5914 - val_mae: 2.2021\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.3120 - mae: 0.8310 - val_loss: 10.5622 - val_mae: 2.3860\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.5547 - mae: 0.9153 - val_loss: 11.2350 - val_mae: 2.3537\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.6321 - mae: 0.9035 - val_loss: 9.8628 - val_mae: 2.3208\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.6179 - mae: 0.9225 - val_loss: 12.0546 - val_mae: 2.5697\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 2.5076 - mae: 1.1940 - val_loss: 11.5517 - val_mae: 2.5225\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.4652 - mae: 1.4081 - val_loss: 10.3828 - val_mae: 2.4136\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.8883 - mae: 1.0495 - val_loss: 11.1657 - val_mae: 2.5742\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 2.0589 - mae: 1.1045 - val_loss: 9.2011 - val_mae: 2.2416\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 2.2645 - mae: 1.1427 - val_loss: 12.0679 - val_mae: 2.4952\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 2.4086 - mae: 1.1850 - val_loss: 11.3728 - val_mae: 2.3777\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 1.5487 - mae: 0.9417 - val_loss: 13.4307 - val_mae: 2.4878\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.2508 - mae: 0.8788 - val_loss: 11.2197 - val_mae: 2.4518\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.4404 - mae: 0.9114 - val_loss: 10.6687 - val_mae: 2.3234\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 1.2699 - mae: 0.8170 - val_loss: 10.5302 - val_mae: 2.3061\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.1923 - mae: 0.7826 - val_loss: 12.2351 - val_mae: 2.3930\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.0986 - mae: 0.7863 - val_loss: 10.1684 - val_mae: 2.2435\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.0974 - mae: 0.7585 - val_loss: 11.4476 - val_mae: 2.3473\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.0099 - mae: 0.7338 - val_loss: 11.5954 - val_mae: 2.4019\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.2614 - mae: 0.8237 - val_loss: 9.2689 - val_mae: 2.2059\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.3372 - mae: 0.8693 - val_loss: 9.9478 - val_mae: 2.3493\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 1.2578 - mae: 0.8049 - val_loss: 12.1889 - val_mae: 2.3722\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.3613 - mae: 0.8572 - val_loss: 8.7341 - val_mae: 2.1556\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.5765 - mae: 0.9618 - val_loss: 11.0322 - val_mae: 2.4512\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.5371 - mae: 0.9458 - val_loss: 11.1684 - val_mae: 2.4505\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2761 - mae: 0.8421 - val_loss: 11.6155 - val_mae: 2.5225\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 2.9987 - mae: 1.4159 - val_loss: 10.8513 - val_mae: 2.4052\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 4.4764 - mae: 1.6862 - val_loss: 11.9126 - val_mae: 2.4536\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 6.3549 - mae: 1.9795 - val_loss: 12.5576 - val_mae: 2.6317\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.3042 - mae: 1.6556 - val_loss: 16.4105 - val_mae: 2.8542\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 3.1003 - mae: 1.3811 - val_loss: 10.0303 - val_mae: 2.2134\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.0917 - mae: 1.1014 - val_loss: 11.2444 - val_mae: 2.3788\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 1.7048 - mae: 0.9921 - val_loss: 10.6140 - val_mae: 2.2484\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.5331 - mae: 0.9424 - val_loss: 12.3044 - val_mae: 2.5137\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.4565 - mae: 0.9198 - val_loss: 9.9070 - val_mae: 2.2510\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.6426 - mae: 0.9468 - val_loss: 11.2385 - val_mae: 2.4508\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.9909 - mae: 1.1616 - val_loss: 11.0874 - val_mae: 2.4697\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2.1038 - mae: 1.1112 - val_loss: 10.4385 - val_mae: 2.2719\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 2.0833 - mae: 1.0873 - val_loss: 11.1639 - val_mae: 2.4036\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 2.2952 - mae: 1.1518 - val_loss: 12.5117 - val_mae: 2.5570\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 2.2093 - mae: 1.1664 - val_loss: 10.6160 - val_mae: 2.3476\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.6669 - mae: 1.0128 - val_loss: 11.9036 - val_mae: 2.5351\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 1.8196 - mae: 1.0577 - val_loss: 9.7268 - val_mae: 2.2486\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.6177 - mae: 0.9725 - val_loss: 11.4863 - val_mae: 2.4934\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.7016 - mae: 0.9611 - val_loss: 13.7916 - val_mae: 2.4994\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.5992 - mae: 0.9365 - val_loss: 12.9039 - val_mae: 2.5538\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.4316 - mae: 0.8964 - val_loss: 11.6396 - val_mae: 2.4860\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.2798 - mae: 0.8459 - val_loss: 9.9275 - val_mae: 2.2073\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1.1357 - mae: 0.7923 - val_loss: 9.7296 - val_mae: 2.2621\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.1159 - mae: 0.7526 - val_loss: 9.5094 - val_mae: 2.1939\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.0627 - mae: 0.7814 - val_loss: 11.4984 - val_mae: 2.4030\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.2145 - mae: 0.8475 - val_loss: 11.0676 - val_mae: 2.3311\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.1703 - mae: 0.8243 - val_loss: 10.7318 - val_mae: 2.3359\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.1679 - mae: 0.8212 - val_loss: 10.7385 - val_mae: 2.3604\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.9582 - mae: 0.7257 - val_loss: 9.4844 - val_mae: 2.2907\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.1109 - mae: 0.7547 - val_loss: 10.2407 - val_mae: 2.3285\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.9434 - mae: 0.6964 - val_loss: 10.0663 - val_mae: 2.2552\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.9435 - mae: 0.6827 - val_loss: 11.1252 - val_mae: 2.2758\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 1.2273 - mae: 0.8382 - val_loss: 12.5850 - val_mae: 2.5080\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.2351 - mae: 0.8325 - val_loss: 10.0236 - val_mae: 2.2859\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1.4677 - mae: 0.9507 - val_loss: 10.6119 - val_mae: 2.3787\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.9223 - mae: 1.0004 - val_loss: 11.0253 - val_mae: 2.5193\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.4964 - mae: 0.9257 - val_loss: 10.5848 - val_mae: 2.4262\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.2945 - mae: 0.8658 - val_loss: 8.8689 - val_mae: 2.1878\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1.2072 - mae: 0.8118 - val_loss: 12.8838 - val_mae: 2.5860\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.9598 - mae: 0.7159 - val_loss: 9.8711 - val_mae: 2.3096\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.9537 - mae: 0.6771 - val_loss: 9.6879 - val_mae: 2.2928\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.8626 - mae: 0.6796 - val_loss: 11.0548 - val_mae: 2.3742\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.8800 - mae: 0.6868 - val_loss: 8.8649 - val_mae: 2.2602\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.9735 - mae: 0.7093 - val_loss: 11.2859 - val_mae: 2.4255\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 1.0656 - mae: 0.7532 - val_loss: 10.5953 - val_mae: 2.3597\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.8483 - mae: 0.6777 - val_loss: 8.6743 - val_mae: 2.2153\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.8944 - mae: 0.6829 - val_loss: 11.6652 - val_mae: 2.4604\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 1.0377 - mae: 0.7762 - val_loss: 9.0802 - val_mae: 2.1917\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.7671 - mae: 0.6165 - val_loss: 10.3074 - val_mae: 2.3428\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.8698 - mae: 0.6941 - val_loss: 11.0832 - val_mae: 2.3940\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.9735 - mae: 0.7385 - val_loss: 10.3172 - val_mae: 2.3364\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.9111 - mae: 0.7221 - val_loss: 9.4586 - val_mae: 2.2238\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.8167 - mae: 0.6801 - val_loss: 10.8695 - val_mae: 2.4107\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.1747 - mae: 0.8410 - val_loss: 11.0919 - val_mae: 2.4989\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.5394 - mae: 0.9516 - val_loss: 11.1460 - val_mae: 2.4423\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.6821 - mae: 0.9851 - val_loss: 8.6970 - val_mae: 2.1619\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.3443 - mae: 0.8709 - val_loss: 12.2724 - val_mae: 2.6390\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.4473 - mae: 0.9247 - val_loss: 12.3180 - val_mae: 2.5068\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.3227 - mae: 0.8643 - val_loss: 10.6526 - val_mae: 2.3400\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 1.3756 - mae: 0.8744 - val_loss: 11.2529 - val_mae: 2.4454\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.0459 - mae: 0.7765 - val_loss: 9.9211 - val_mae: 2.2518\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 1.0173 - mae: 0.7745 - val_loss: 9.7323 - val_mae: 2.3398\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.1208 - mae: 0.8037 - val_loss: 10.3481 - val_mae: 2.2314\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1.0777 - mae: 0.7726 - val_loss: 10.1091 - val_mae: 2.2704\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.9645 - mae: 0.7245 - val_loss: 9.5626 - val_mae: 2.2660\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.8315 - mae: 0.6866 - val_loss: 11.1404 - val_mae: 2.3590\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.0771 - mae: 0.7797 - val_loss: 11.2856 - val_mae: 2.4502\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.2958 - mae: 0.8911 - val_loss: 10.6697 - val_mae: 2.3502\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.9173 - mae: 0.7318 - val_loss: 9.9049 - val_mae: 2.2574\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.7817 - mae: 0.6529 - val_loss: 9.9878 - val_mae: 2.2686\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6938 - mae: 0.6007 - val_loss: 9.4337 - val_mae: 2.2358\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6779 - mae: 0.6015 - val_loss: 10.3269 - val_mae: 2.3419\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.7187 - mae: 0.5744 - val_loss: 10.1775 - val_mae: 2.2830\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.8033 - mae: 0.6419 - val_loss: 11.6872 - val_mae: 2.5993\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.5272 - mae: 0.9557 - val_loss: 10.5265 - val_mae: 2.3697\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 1.0917 - mae: 0.7428 - val_loss: 10.2258 - val_mae: 2.3525\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.8620 - mae: 0.7251 - val_loss: 10.7857 - val_mae: 2.3056\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5934 - mae: 0.9944 - val_loss: 10.2795 - val_mae: 2.3959\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.0711 - mae: 1.1414 - val_loss: 12.5565 - val_mae: 2.5182\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.3357 - mae: 1.1584 - val_loss: 11.3700 - val_mae: 2.4705\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.2069 - mae: 0.8598 - val_loss: 11.6385 - val_mae: 2.4239\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.1491 - mae: 0.8080 - val_loss: 9.9376 - val_mae: 2.2723\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.8680 - mae: 0.6994 - val_loss: 10.7209 - val_mae: 2.4080\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.1760 - mae: 0.8421 - val_loss: 12.0842 - val_mae: 2.4067\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2480 - mae: 0.8610 - val_loss: 10.9500 - val_mae: 2.4035\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.0797 - mae: 0.7989 - val_loss: 9.6105 - val_mae: 2.3164\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 1.4625 - mae: 0.9239 - val_loss: 9.4362 - val_mae: 2.2993\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.9320 - mae: 0.7340 - val_loss: 9.6834 - val_mae: 2.3366\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.8817 - mae: 0.6776 - val_loss: 11.6450 - val_mae: 2.4802\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8212 - mae: 0.6816 - val_loss: 8.5698 - val_mae: 2.2003\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0037 - mae: 0.7136 - val_loss: 14.4377 - val_mae: 2.6186\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.9609 - mae: 0.6980 - val_loss: 10.2231 - val_mae: 2.3510\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.0121 - mae: 0.7364 - val_loss: 11.3518 - val_mae: 2.4008\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.1233 - mae: 0.7962 - val_loss: 9.0221 - val_mae: 2.2231\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.2519 - mae: 0.8391 - val_loss: 10.1470 - val_mae: 2.5426\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 1.2218 - mae: 0.8275 - val_loss: 10.6879 - val_mae: 2.4379\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.3624 - mae: 0.9129 - val_loss: 11.7964 - val_mae: 2.5216\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.1614 - mae: 0.8620 - val_loss: 10.0003 - val_mae: 2.2908\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.2589 - mae: 0.8575 - val_loss: 11.8889 - val_mae: 2.5198\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.9441 - mae: 0.7210 - val_loss: 9.1890 - val_mae: 2.2124\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6770 - mae: 0.6080 - val_loss: 11.2255 - val_mae: 2.4182\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.5795 - mae: 0.5544 - val_loss: 10.9110 - val_mae: 2.3315\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.6110 - mae: 0.5601 - val_loss: 11.1939 - val_mae: 2.4188\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.5251 - mae: 0.5212 - val_loss: 10.0846 - val_mae: 2.3156\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.5923 - mae: 0.5783 - val_loss: 10.5978 - val_mae: 2.4324\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.7565 - mae: 0.6654 - val_loss: 10.6242 - val_mae: 2.3283\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.9544 - mae: 0.7050 - val_loss: 10.1546 - val_mae: 2.3337\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.1055 - mae: 0.7849 - val_loss: 10.9921 - val_mae: 2.6113\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.0688 - mae: 0.7638 - val_loss: 10.0039 - val_mae: 2.3390\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.7537 - mae: 0.6496 - val_loss: 9.9613 - val_mae: 2.3422\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.6660 - mae: 0.6013 - val_loss: 10.7043 - val_mae: 2.3386\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.8802 - mae: 0.7395 - val_loss: 10.0332 - val_mae: 2.3374\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.7630 - mae: 0.6482 - val_loss: 10.4363 - val_mae: 2.3803\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.7616 - mae: 0.6901 - val_loss: 10.6755 - val_mae: 2.3586\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.6225 - mae: 0.5725 - val_loss: 10.6928 - val_mae: 2.3136\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.6745 - mae: 0.6038 - val_loss: 10.2865 - val_mae: 2.3918\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.5247 - mae: 0.5177 - val_loss: 10.5948 - val_mae: 2.3451\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.5201 - mae: 0.4971 - val_loss: 10.4184 - val_mae: 2.3288\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4773 - mae: 0.4965 - val_loss: 10.3559 - val_mae: 2.3642\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.4425 - mae: 0.4529 - val_loss: 10.2862 - val_mae: 2.3516\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.4474 - mae: 0.4680 - val_loss: 10.2709 - val_mae: 2.3233\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.3930 - mae: 0.4308 - val_loss: 11.0671 - val_mae: 2.3613\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.4085 - mae: 0.4506 - val_loss: 10.0476 - val_mae: 2.3625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1erMMEoeR0rB"
      },
      "source": [
        "### 모델 평가 \n",
        "- `evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo0n0SaZRbD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d633ac9-3281-46be-c786-87c068e2841a"
      },
      "source": [
        "model.evaluate(X_test, y_test) #test data로 평가한 결과 "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 188.8930 - mae: 10.0901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[188.89297485351562, 10.090087890625]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl98Ql_8nvf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04978504-6d1c-4d68-b7b5-02c879420923"
      },
      "source": [
        "print(history.history.keys()) #처음 보는데요 "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOgcoBclnsJ7"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtICFsIvVpF2"
      },
      "source": [
        "### K-Fold 교차 검증\n",
        "\n",
        "- 데이터셋의 크기가 매우 작은 경우에  \n",
        "  [훈련, 검증, 테스트] 데이터로 나누게 되면 과소적합이 일어날 확률이 높음\n",
        "\n",
        "- 이를 해결하기 위해 K-Fold 교차 검증 실행\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://scikit-learn.org/stable/modules/cross_validation.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giNUN6mwWSDO"
      },
      "source": [
        "### 모델 재구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIFRNBlYWzBc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60EvVZ9qR5v6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HiJbnWrWkXY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS3uTP6oXDzr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMCmLyLYI2l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_0YHP-YUHU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJB6bWP_Y80O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwxuiq4cITg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}